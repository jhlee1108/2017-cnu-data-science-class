{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textFile = sc.textFile(\"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count() # Number of items in this RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Apache Spark'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first() # First item in this RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linesWithSpark = textFile.filter(lambda line: \"Spark\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many lines contain \"Spark\"?\n",
    "textFile.filter(lambda line: \"Spark\" in line).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.map(lambda line: len(line.split()))\\\n",
    "        .reduce(lambda a, b: a if (a > b) else b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max(a, b):\n",
    "    if a > b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "textFile.map(lambda line: len(line.split())).reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordCounts = textFile.flatMap(lambda line: line.split())\\\n",
    "                        .map(lambda word: (word, 1))\\\n",
    "                        .reduceByKey(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guide,', 1),\n",
       " ('APIs', 1),\n",
       " ('environment', 1),\n",
       " ('name', 1),\n",
       " ('is', 6),\n",
       " ('developing', 1),\n",
       " ('[\"Parallel', 1),\n",
       " ('[http://spark.apache.org/developer-tools.html](the', 1),\n",
       " ('development', 1),\n",
       " ('tools', 1),\n",
       " ('system', 1),\n",
       " ('-T', 1),\n",
       " ('shell:', 2),\n",
       " ('Pi', 1),\n",
       " ('find', 1),\n",
       " ('Developer', 1),\n",
       " ('sc.parallelize(1', 1),\n",
       " ('Configuration', 1),\n",
       " ('run', 7),\n",
       " ('computing', 1),\n",
       " ('start', 1),\n",
       " ('return', 2),\n",
       " ('see', 3),\n",
       " ('Python,', 2),\n",
       " ('directory.', 1),\n",
       " ('rich', 1),\n",
       " ('processing.', 1),\n",
       " ('\"local[N]\"', 1),\n",
       " ('graph', 1),\n",
       " ('you', 4),\n",
       " ('data', 1),\n",
       " ('using:', 1),\n",
       " ('package', 1),\n",
       " ('Building', 1),\n",
       " ('mesos://', 1),\n",
       " ('do', 2),\n",
       " ('several', 1),\n",
       " ('A', 1),\n",
       " ('The', 1),\n",
       " ('MASTER', 1),\n",
       " ('\"local\"', 1),\n",
       " ('by', 1),\n",
       " ('programming', 1),\n",
       " ('for', 12),\n",
       " ('Online', 1),\n",
       " ('scala>', 1),\n",
       " ('a', 8),\n",
       " ('on', 7),\n",
       " ('overview', 1),\n",
       " ('basic', 1),\n",
       " ('optimized', 1),\n",
       " ('latest', 1),\n",
       " ('package.)', 1),\n",
       " ('Hadoop,', 2),\n",
       " ('module,', 1),\n",
       " ('More', 1),\n",
       " ('[project', 1),\n",
       " ('Useful', 1),\n",
       " ('1000:', 2),\n",
       " ('uses', 1),\n",
       " ('[building', 1),\n",
       " ('URL,', 1),\n",
       " ('example:', 1),\n",
       " ('README', 1),\n",
       " ('be', 2),\n",
       " ('help', 1),\n",
       " ('file', 1),\n",
       " ('building', 2),\n",
       " ('learning,', 1),\n",
       " ('clean', 1),\n",
       " ('instructions.', 1),\n",
       " ('[Apache', 1),\n",
       " ('build', 4),\n",
       " ('Shell', 2),\n",
       " ('including', 4),\n",
       " ('MLlib', 1),\n",
       " ('that', 2),\n",
       " ('Maven](http://maven.apache.org/).', 1),\n",
       " ('Python', 2),\n",
       " ('to', 17),\n",
       " ('abbreviated', 1),\n",
       " ('not', 1),\n",
       " ('Spark.', 1),\n",
       " ('Documentation', 1),\n",
       " ('library', 1),\n",
       " ('general', 3),\n",
       " ('fast', 1),\n",
       " ('high-level', 1),\n",
       " ('build/mvn', 1),\n",
       " ('YARN,', 1),\n",
       " ('one', 3),\n",
       " ('info', 1),\n",
       " ('examples', 2),\n",
       " ('built', 1),\n",
       " ('information', 1),\n",
       " ('cluster', 2),\n",
       " ('Hadoop', 3),\n",
       " ('`./bin/run-example', 1),\n",
       " ('For', 3),\n",
       " ('more', 1),\n",
       " ('easiest', 1),\n",
       " ('tests', 2),\n",
       " ('tips,', 1),\n",
       " ('setup', 1),\n",
       " ('way', 1),\n",
       " ('machine', 1),\n",
       " ('prefer', 1),\n",
       " ('Scala', 2),\n",
       " ('[Contribution', 1),\n",
       " ('To', 2),\n",
       " ('1000).count()', 1),\n",
       " ('which', 2),\n",
       " ('threads.', 1),\n",
       " ('This', 2),\n",
       " ('-DskipTests', 1),\n",
       " ('variable', 1),\n",
       " ('>>>', 1),\n",
       " ('Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
       " ('R,', 1),\n",
       " ('other', 1),\n",
       " ('use', 3),\n",
       " ('./bin/run-example', 2),\n",
       " ('storage', 1),\n",
       " ('Streaming', 1),\n",
       " ('./dev/run-tests', 1),\n",
       " ('Example', 1),\n",
       " ('[run', 1),\n",
       " ('set', 2),\n",
       " ('at', 2),\n",
       " ('documentation', 3),\n",
       " ('of', 5),\n",
       " ('Interactive', 2),\n",
       " ('processing,', 1),\n",
       " ('./bin/spark-shell', 1),\n",
       " ('[\"Building', 1),\n",
       " ('talk', 1),\n",
       " ('computation', 1),\n",
       " ('Maven,', 1),\n",
       " ('And', 1),\n",
       " ('than', 1),\n",
       " ('different', 1),\n",
       " ('documentation,', 1),\n",
       " ('using', 5),\n",
       " ('Tests', 1),\n",
       " ('print', 1),\n",
       " ('<class>', 1),\n",
       " ('its', 1),\n",
       " ('sample', 1),\n",
       " ('Scala,', 1),\n",
       " ('particular', 2),\n",
       " ('with', 4),\n",
       " ('detailed', 2),\n",
       " ('must', 1),\n",
       " ('the', 24),\n",
       " ('params', 1),\n",
       " ('<http://spark.apache.org/>', 1),\n",
       " ('programs', 2),\n",
       " ('sc.parallelize(range(1000)).count()', 1),\n",
       " ('changed', 1),\n",
       " ('first', 1),\n",
       " ('following', 2),\n",
       " ('3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).',\n",
       "  1),\n",
       " ('runs.', 1),\n",
       " ('Please', 4),\n",
       " ('SQL', 2),\n",
       " ('You', 4),\n",
       " ('core', 1),\n",
       " ('configure', 1),\n",
       " ('It', 2),\n",
       " ('Hive', 2),\n",
       " ('thread', 1),\n",
       " ('review', 1),\n",
       " ('Testing', 1),\n",
       " ('running', 1),\n",
       " ('locally', 2),\n",
       " ('Programs', 1),\n",
       " ('have', 1),\n",
       " ('MASTER=spark://host:7077', 1),\n",
       " ('Once', 1),\n",
       " ('or', 3),\n",
       " ('higher-level', 1),\n",
       " ('how', 3),\n",
       " ('provides', 1),\n",
       " ('locally.', 1),\n",
       " ('systems.', 1),\n",
       " ('when', 1),\n",
       " ('option', 1),\n",
       " ('cluster.', 1),\n",
       " ('started', 1),\n",
       " ('version', 1),\n",
       " ('instance:', 1),\n",
       " ('also', 4),\n",
       " ('in', 6),\n",
       " ('if', 4),\n",
       " ('same', 1),\n",
       " ('downloaded', 1),\n",
       " ('Versions', 1),\n",
       " ('Alternatively,', 1),\n",
       " ('Thriftserver', 1),\n",
       " ('project', 1),\n",
       " ('pre-built', 1),\n",
       " ('[params]`.', 1),\n",
       " ('Try', 1),\n",
       " ('Maven', 1),\n",
       " ('supports', 2),\n",
       " ('package.', 1),\n",
       " ('About', 1),\n",
       " ('page).', 1),\n",
       " ('need', 1),\n",
       " ('should', 2),\n",
       " ('and', 9),\n",
       " ('distributions.', 1),\n",
       " ('web', 1),\n",
       " ('command,', 2),\n",
       " ('example', 3),\n",
       " ('are', 1),\n",
       " ('Contributing', 1),\n",
       " ('will', 1),\n",
       " ('no', 1),\n",
       " ('from', 1),\n",
       " ('project.', 1),\n",
       " ('GraphX', 1),\n",
       " ('your', 1),\n",
       " ('DataFrames,', 1),\n",
       " ('distribution', 1),\n",
       " ('#', 1),\n",
       " ('./bin/pyspark', 1),\n",
       " ('engine', 1),\n",
       " ('IDE,', 1),\n",
       " ('get', 1),\n",
       " ('builds', 1),\n",
       " ('Note', 1),\n",
       " ('analysis.', 1),\n",
       " ('tests](http://spark.apache.org/developer-tools.html#individual-tests).', 1),\n",
       " ('usage', 1),\n",
       " ('only', 1),\n",
       " ('available', 1),\n",
       " ('them,', 1),\n",
       " ('comes', 1),\n",
       " ('N', 1),\n",
       " ('graphs', 1),\n",
       " ('Hadoop-supported', 1),\n",
       " ('Many', 1),\n",
       " ('Because', 1),\n",
       " ('page](http://spark.apache.org/documentation.html).', 1),\n",
       " ('Spark](#building-spark).', 1),\n",
       " ('run:', 1),\n",
       " ('[\"Specifying', 1),\n",
       " ('built,', 1),\n",
       " ('guidance', 2),\n",
       " ('guide](http://spark.apache.org/contributing.html)', 1),\n",
       " ('an', 4),\n",
       " ('Tools', 1),\n",
       " ('Guide](http://spark.apache.org/docs/latest/configuration.html)', 1),\n",
       " ('Data.', 1),\n",
       " ('individual', 1),\n",
       " ('Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)',\n",
       "  1),\n",
       " ('spark://', 1),\n",
       " ('requires', 1),\n",
       " ('class', 2),\n",
       " ('programs,', 1),\n",
       " ('can', 7),\n",
       " ('this', 1),\n",
       " ('refer', 2),\n",
       " ('Java,', 1),\n",
       " ('contributing', 1),\n",
       " ('`examples`', 2),\n",
       " ('Running', 1),\n",
       " ('[Configuration', 1),\n",
       " ('contains', 1),\n",
       " ('(You', 1),\n",
       " ('through', 1),\n",
       " ('stream', 1),\n",
       " ('against', 1),\n",
       " ('\"yarn\"', 1),\n",
       " ('Spark', 16),\n",
       " ('Apache', 1),\n",
       " ('online', 1),\n",
       " ('HDFS', 1),\n",
       " ('site,', 1),\n",
       " ('thread,', 1),\n",
       " ('versions', 1),\n",
       " ('SparkPi', 2),\n",
       " ('protocols', 1),\n",
       " ('submit', 1),\n",
       " ('given.', 1),\n",
       " ('##', 9),\n",
       " ('Big', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\")\\\n",
    "                .load(\"data/mllib/sample_kmeans_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|           (3,[],[])|\n",
      "|  1.0|(3,[0,1,2],[0.1,0...|\n",
      "|  2.0|(3,[0,1,2],[0.2,0...|\n",
      "|  3.0|(3,[0,1,2],[9.0,9...|\n",
      "|  4.0|(3,[0,1,2],[9.1,9...|\n",
      "|  5.0|(3,[0,1,2],[9.2,9...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 0.11999999999994547\n"
     ]
    }
   ],
   "source": [
    "# Evaluate clustering by computing \n",
    "# Within Set Sum of Squared Errors.\n",
    "wssse = model.computeCost(dataset)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[ 0.1  0.1  0.1]\n",
      "[ 9.1  9.1  9.1]\n"
     ]
    }
   ],
   "source": [
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. sokulee data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sleep = spark.read\\\n",
    "            .json('/home/hadoop/sokulee/*/*_sleep.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|               sleep|      summary|\n",
      "+--------------------+-------------+\n",
      "|[[0,0,1,2016-05-0...|[1199,2,1219]|\n",
      "|[[0,0,22,2016-04-...| [993,3,1082]|\n",
      "|[[8,58,44,2016-05...| [880,1,1040]|\n",
      "|[[1,2,24,2016-04-...|  [915,1,962]|\n",
      "|[[0,0,1,2016-05-0...|  [959,1,960]|\n",
      "|[[8,15,38,2016-05...|  [859,1,950]|\n",
      "|[[2,2,45,2016-05-...|  [786,2,902]|\n",
      "|[[1,4,33,2016-05-...|  [820,1,884]|\n",
      "|[[5,17,22,2016-05...|  [809,1,873]|\n",
      "|[[2,4,12,2016-05-...|  [823,2,856]|\n",
      "|[[2,4,12,2016-05-...|  [823,2,856]|\n",
      "|[[1,3,25,2016-04-...|  [783,2,848]|\n",
      "|[[2,5,40,2016-04-...|  [782,1,857]|\n",
      "|[[4,21,42,2016-05...|  [759,1,851]|\n",
      "|[[4,21,42,2016-05...|  [759,1,851]|\n",
      "|[[2,3,40,2016-04-...|  [735,2,839]|\n",
      "|[[2,2,34,2016-04-...|  [783,1,841]|\n",
      "|[[3,10,38,2016-04...|  [746,1,837]|\n",
      "|[[1,1,30,2016-04-...|  [753,2,821]|\n",
      "|[[1,4,13,2016-05-...|  [763,1,819]|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sleep.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_steps = spark.read\\\n",
    "            .json('/home/hadoop/sokulee/*/*_steps.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------+------+-------+\n",
      "|    activities-steps|activities-steps-intraday|errors|success|\n",
      "+--------------------+-------------------------+------+-------+\n",
      "|[[2016-04-04,42083]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-05-14,44756]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-05-14,38608]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-05-06,42330]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-09,35277]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-08,30282]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-09,33941]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-09,33941]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-12,32075]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-12,32075]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-09,29336]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-05-01,31228]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-04,31950]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-04,31950]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-05-17,30683]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-23,31421]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-04,30661]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-05-16,33414]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-17,31812]]|     [WrappedArray([00...|  null|   null|\n",
      "|[[2016-04-15,29090]]|     [WrappedArray([00...|  null|   null|\n",
      "+--------------------+-------------------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_steps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sleep: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- awakeCount: long (nullable = true)\n",
      " |    |    |-- awakeDuration: long (nullable = true)\n",
      " |    |    |-- awakeningsCount: long (nullable = true)\n",
      " |    |    |-- dateOfSleep: string (nullable = true)\n",
      " |    |    |-- duration: long (nullable = true)\n",
      " |    |    |-- efficiency: long (nullable = true)\n",
      " |    |    |-- isMainSleep: boolean (nullable = true)\n",
      " |    |    |-- logId: long (nullable = true)\n",
      " |    |    |-- minuteData: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- dateTime: string (nullable = true)\n",
      " |    |    |    |    |-- value: string (nullable = true)\n",
      " |    |    |-- minutesAfterWakeup: long (nullable = true)\n",
      " |    |    |-- minutesAsleep: long (nullable = true)\n",
      " |    |    |-- minutesAwake: long (nullable = true)\n",
      " |    |    |-- minutesToFallAsleep: long (nullable = true)\n",
      " |    |    |-- restlessCount: long (nullable = true)\n",
      " |    |    |-- restlessDuration: long (nullable = true)\n",
      " |    |    |-- startTime: string (nullable = true)\n",
      " |    |    |-- timeInBed: long (nullable = true)\n",
      " |-- summary: struct (nullable = true)\n",
      " |    |-- totalMinutesAsleep: long (nullable = true)\n",
      " |    |-- totalSleepRecords: long (nullable = true)\n",
      " |    |-- totalTimeInBed: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sleep.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- activities-steps: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- dateTime: string (nullable = true)\n",
      " |    |    |-- value: string (nullable = true)\n",
      " |-- activities-steps-intraday: struct (nullable = true)\n",
      " |    |-- dataset: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- time: string (nullable = true)\n",
      " |    |    |    |-- value: long (nullable = true)\n",
      " |    |-- datasetInterval: long (nullable = true)\n",
      " |    |-- datasetType: string (nullable = true)\n",
      " |-- errors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- errorType: string (nullable = true)\n",
      " |    |    |-- message: string (nullable = true)\n",
      " |-- success: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_steps.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sleep_total_minutes_sleep = df_sleep.select(\n",
    "                df_sleep['summary']['totalMinutesAsleep'])\n",
    "sleep_total_time_in_bed = df_sleep.select(\n",
    "                df_sleep['summary']['totalTimeInBed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|summary.totalMinutesAsleep|\n",
      "+--------------------------+\n",
      "|                      1199|\n",
      "|                       993|\n",
      "|                       880|\n",
      "|                       915|\n",
      "|                       959|\n",
      "|                       859|\n",
      "|                       786|\n",
      "|                       820|\n",
      "|                       809|\n",
      "|                       823|\n",
      "|                       823|\n",
      "|                       783|\n",
      "|                       782|\n",
      "|                       759|\n",
      "|                       759|\n",
      "|                       735|\n",
      "|                       783|\n",
      "|                       746|\n",
      "|                       753|\n",
      "|                       763|\n",
      "+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sleep_total_minutes_sleep.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|summary.totalTimeInBed|\n",
      "+----------------------+\n",
      "|                  1219|\n",
      "|                  1082|\n",
      "|                  1040|\n",
      "|                   962|\n",
      "|                   960|\n",
      "|                   950|\n",
      "|                   902|\n",
      "|                   884|\n",
      "|                   873|\n",
      "|                   856|\n",
      "|                   856|\n",
      "|                   848|\n",
      "|                   857|\n",
      "|                   851|\n",
      "|                   851|\n",
      "|                   839|\n",
      "|                   841|\n",
      "|                   837|\n",
      "|                   821|\n",
      "|                   819|\n",
      "+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sleep_total_time_in_bed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "|avg(summary['totalMinutesAsleep'])|min(summary['totalMinutesAsleep'])|max(summary['totalMinutesAsleep'])|\n",
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "|                306.74880239520957|                                 0|                              1199|\n",
      "+----------------------------------+----------------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sleep.select(mean(df_sleep['summary']['totalMinutesAsleep']), \n",
    "                   min(df_sleep['summary']['totalMinutesAsleep']), \n",
    "                   max(df_sleep['summary']['totalMinutesAsleep'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------------------------+\n",
      "|avg(summary['totalTimeInBed'])|min(summary['totalTimeInBed'])|max(summary['totalTimeInBed'])|\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "|            332.98952095808386|                             0|                          1219|\n",
      "+------------------------------+------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sleep.select(mean(df_sleep['summary']['totalTimeInBed']), \n",
    "                   min(df_sleep['summary']['totalTimeInBed']), \n",
    "                   max(df_sleep['summary']['totalTimeInBed'])).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
